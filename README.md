# Обучение малой RecRNN модели в Kaggle

## Инструкции по запуску

В этом репозитории представлены два ноутбука для запуска в среде Kaggle:

1. `standard_train_kaggle.ipynb` - стандартный подход к обучению с использованием полной последовательности токенов
2. `optimized_train_kaggle.ipynb` - оптимизированный подход с использованием предсказания одного целевого токена

### Первые шаги в Kaggle

1. Создайте новый ноутбук в Kaggle
2. В правом меню выберите "File" -> "Import Notebook"
3. Загрузите один из ноутбуков (standard_train_kaggle.ipynb или optimized_train_kaggle.ipynb)
4. Обновите URL репозитория в первой ячейке кода, заменив `https://your-repo-url.git` на URL вашего репозитория

### Настройка ноутбука в Kaggle

1. Для ускорения обучения, в настройках ноутбука (⚙️) выберите:
   - Accelerator: GPU (P100 или T4 GPU)
   - Dataset: добавьте ваш репозиторий

2. При необходимости, настройте параметры обучения:
   - `--hidden-size` - размер скрытого слоя (768 по умолчанию) 
   - `--batch-size` - размер батча (16-32 по умолчанию)

### Сравнение подходов:

1. **Стандартный подход**:
   - Использует полную автоматическую генерацию последовательностей
   - Обучает модель предсказывать полную последовательность
   - Более ресурсоемкий

2. **Оптимизированный подход**:
   - Преобразует задачу в классификацию одного токена
   - Значительно уменьшает требования к памяти
   - Ускоряет обучение и сходимость
   - Два варианта запуска:
     - `model_trainer.py` - специализированная реализация для задачи классификации
     - `run_small_model.py --optimize-data` - стандартный тренер с оптимизированными данными

## Структура проекта

```
recurrent-pretraining/
├── analyze_dataset.py         # Анализ структуры данных
├── config/
│   └── small_recurnn.py       # Конфигурация малой версии модели
├── data/                      # Директория с данными
│   ├── train.json             # Тренировочные данные
│   ├── valid.json             # Валидационные данные 
│   ├── test.json              # Тестовые данные
│   └── vocab.json             # Словарь токенов
├── prepare_tokenized_data.py  # Стандартная подготовка данных
├── prepare_optimized_data.py  # Оптимизированная подготовка данных с одним целевым токеном  
├── optimized_collator.py      # Коллатор для оптимизированных данных
├── run_small_model.py         # Основной скрипт обучения
├── model_trainer.py           # Специализированный тренер для классификации
└── simple_tokenizer.py        # Простой токенизатор
```

## Сохранение моделей

После завершения обучения, обе версии ноутбуков сохраняют модели в директории `/kaggle/working/saved_models/`. Эти файлы будут доступны для скачивания после завершения выполнения ноутбука.
